{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0tyra0NWJvI"
   },
   "source": [
    "## MNIST machine learning exercise\n",
    "\n",
    "In this exercise we will compare the performance of three different modeling approaches at predicting handwritten numbers. \n",
    "\n",
    "We use the MNIST data set;\n",
    "\n",
    "![mnist data](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmAFVhDJXFBb"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "48VnFR9cXFP0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI7yVb-VW2zi"
   },
   "source": [
    "## Load data and explore/get to know the data structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST digits dataset. It's originally from UCI machine learning library, but included in SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "M8CjaVlYW2Jx",
    "outputId": "e90a4dd3-3781-477f-b02f-97ac3e75be91"
   },
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits() # sklearn includes this data set .. https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset is stored in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5pPXrazAfUoL",
    "outputId": "593b0df0-7b98-4c9b-e01d-36930d653723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note thjat there are 1797 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTQ7qNp4ffaW",
    "outputId": "3d267533-ac01-4747-abee-369aae5d3d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are 8x8 grid of values epresenting the gray level for each pixel (16 levels of grey -- from 0 (black) to 15 (white)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "B0ZaSvLlfva0",
    "outputId": "7735e16a-6f2e-41cd-e4e3-55c1dbd5a89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this, we simple turn this into a one dimensional array (so we will x1, x2, ... x63, x64). This has already been done for us, and is stored in the data key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "sjDP19CWfT6S",
    "outputId": "f3643de4-6fc9-4810-d5d5-21fb633970fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Pi5Fvsd_dry5",
    "outputId": "d61e56b6-99c4-486c-b4fa-523f3cb7f1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(mnist.target[0])\n",
    "print(mnist.target[1])\n",
    "print(mnist.target[2])\n",
    "print(mnist.target[3])\n",
    "print(mnist.target[4])\n",
    "print(mnist.target[5])\n",
    "print(mnist.target[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to display a sample of these images from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qW162_28WC60",
    "outputId": "c7bf771d-ebd1-4a42-e9e4-719d243b814a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.choice(range(0,len(mnist.images)), 4): # choose 4 at random\n",
    "  plt.imshow(mnist.images[i], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 431 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(64))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) # final layer, 10 categories\n",
    "\n",
    "\n",
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# if you want to overide the defaults for the optimizer....\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 1s 23ms/step - loss: 4.3834 - accuracy: 0.1058 - val_loss: 2.0770 - val_accuracy: 0.1972\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8042 - accuracy: 0.3834 - val_loss: 1.4751 - val_accuracy: 0.5472\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.2955 - accuracy: 0.6374 - val_loss: 1.0355 - val_accuracy: 0.7528\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8575 - accuracy: 0.7919 - val_loss: 0.6566 - val_accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.8733 - val_loss: 0.4344 - val_accuracy: 0.8778\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.3702 - accuracy: 0.8998 - val_loss: 0.3251 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2794 - accuracy: 0.9241 - val_loss: 0.2656 - val_accuracy: 0.9167\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.2213 - accuracy: 0.9395 - val_loss: 0.2303 - val_accuracy: 0.9194\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1833 - accuracy: 0.9499 - val_loss: 0.2215 - val_accuracy: 0.9194\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.9562 - val_loss: 0.1843 - val_accuracy: 0.9306\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1244 - accuracy: 0.9645 - val_loss: 0.1681 - val_accuracy: 0.9306\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9722 - val_loss: 0.1695 - val_accuracy: 0.9222\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9763 - val_loss: 0.1418 - val_accuracy: 0.9444\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9840 - val_loss: 0.1376 - val_accuracy: 0.9583\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9833 - val_loss: 0.1289 - val_accuracy: 0.9472\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9868 - val_loss: 0.1242 - val_accuracy: 0.9583\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9903 - val_loss: 0.1134 - val_accuracy: 0.9611\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9916 - val_loss: 0.1116 - val_accuracy: 0.9611\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9944 - val_loss: 0.1138 - val_accuracy: 0.9611\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9937 - val_loss: 0.0993 - val_accuracy: 0.9611\n",
      "CPU times: total: 1.84 s\n",
      "Wall time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09929009526968002, 0.9611111283302307]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.10\n",
      "accuracy: 96.11%\n"
     ]
    }
   ],
   "source": [
    "# let's format this into a better output...\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=64))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 1s 20ms/step - loss: 1.4874 - accuracy: 0.6117 - val_loss: 0.3504 - val_accuracy: 0.8722\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.9116 - val_loss: 0.2008 - val_accuracy: 0.9306\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1354 - accuracy: 0.9492 - val_loss: 0.1477 - val_accuracy: 0.9444\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9743 - val_loss: 0.0980 - val_accuracy: 0.9611\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 0.1690 - val_accuracy: 0.9472\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0568 - accuracy: 0.9805 - val_loss: 0.1051 - val_accuracy: 0.9778\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 0.1097 - val_accuracy: 0.9722\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.1933 - val_accuracy: 0.9556\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0410 - accuracy: 0.9833 - val_loss: 0.1182 - val_accuracy: 0.9639\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0494 - accuracy: 0.9875 - val_loss: 0.2339 - val_accuracy: 0.9389\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 0.9777 - val_loss: 0.1710 - val_accuracy: 0.9556\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0717 - accuracy: 0.9840 - val_loss: 0.2170 - val_accuracy: 0.9472\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9819 - val_loss: 0.2854 - val_accuracy: 0.9361\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9805 - val_loss: 0.3059 - val_accuracy: 0.9444\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9701 - val_loss: 0.1529 - val_accuracy: 0.9556\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 0.0990 - val_accuracy: 0.9667\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.1055 - val_accuracy: 0.9722\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9916 - val_loss: 0.0722 - val_accuracy: 0.9750\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0479 - val_accuracy: 0.9806\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 0.0818 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08181864023208618, 0.9777777791023254]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.08\n",
      "accuracy: 97.78%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Using cached scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\saisi\\anaconda3\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\saisi\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\saisi\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\saisi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\saisi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\saisi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saisi\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=64)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    ann.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on dense layers and initializers, see the following:\n",
    "* https://keras.io/api/layers/core_layers/dense/\n",
    "* https://keras.io/api/layers/initializers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023D3D53BF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023D3EFF2D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOig4eSm144+FaPk1GKk187",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist_compete_3_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
